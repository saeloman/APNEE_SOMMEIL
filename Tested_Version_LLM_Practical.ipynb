{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeloman/APNEE_SOMMEIL/blob/main/Tested_Version_LLM_Practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# LLM Practical\n",
        "\n",
        "<img src=\"https://www.marktechpost.com/wp-content/uploads/2023/05/Blog-Banner-3.jpg\" width=\"60%\" />\n",
        "\n",
        "\n",
        "© .\n",
        "\n",
        "**Author: ALIAMINI **\n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "Bienvenue dans votre Practical sur les LLMs —votre porte d'entrée vers le monde fascinant des Modèles de Langage de Grande Taille !\n",
        "\n",
        "Dans ce tutoriel, vous aurez l'occasion de vous exercer à entraîner votre propre Modèle de Langage (LLM) ! Préparez-vous à explorer comment ces systèmes d'IA impressionnants créent des textes aussi réalistes et captivants. Partons ensemble pour ce voyage passionnant et déverrouillons les secrets des LLMs ! 🚀📚\n",
        "\n",
        "**Prérequis :**\n",
        "\n",
        "* Bases en Python.\n",
        "* Connaissances introductives en Machine Learning.\n",
        "* Connaissances introductives en NLP.\n",
        "\n",
        "NB: Ce notebook utilise le framework JAX.\n",
        "\n",
        "**Plan :**\n",
        "\n",
        ">[Installations & Importations](#scrollTo=6EqhIg1odqg0)\n",
        "\n",
        ">[Entraînement de votre LLM](#scrollTo=wmt3tp38G90A)\n",
        "\n",
        ">>[1. Objectif d'entraînement Intermédiaire](#scrollTo=jGKuXIJJyyo8)\n",
        "\n",
        ">>[2. Entraînement des modèles Avancés](#scrollTo=4CSfvGj__RGA)\n",
        "\n",
        ">>[3. Inspecter le LLM entraîné Débutant](#scrollTo=pGv9c2AFmF4V)\n",
        "\n",
        ">[Conclusion](#scrollTo=15296-QL3-y3)\n",
        "\n",
        "**Avant de commencer :**\n",
        "\n",
        "Pour ce TP, vous aurez besoin d'utiliser un GPU pour accélérer l'entraînement. Pour ce faire, allez dans le menu \"Exécution\" de Colab, sélectionnez \"Modifier le type d'exécution\", puis dans le menu popup, choisissez \"T4 GPU\" dans la boîte \"Accélérateur matériel\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DKJ2Hc1zzadi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EqhIg1odqg0"
      },
      "source": [
        "## Installations & Importations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4boGA9rYdt9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9fb245-8428-40cc-9036-4e767766dcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting umap-learn\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.13 umap-learn-0.5.7\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.8.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (24.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUn GPU est connecté.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        }
      ],
      "source": [
        "# Installer les bibliothèques nécessaires pour le deep learning, le NLP et la visualisation\n",
        "!pip install transformers datasets  # Bibliothèques Transformers et datasets pour les tâches de NLP\n",
        "!pip install seaborn umap-learn     # Seaborn pour la visualisation, UMAP pour la réduction dimensionnelle\n",
        "!pip install livelossplot           # LiveLossPlot pour suivre les progrès de l'entraînement du modèle\n",
        "!pip install -q transformers[torch] # Transformers avec le backend PyTorch\n",
        "!pip install -q peft                # Bibliothèque de fine-tuning efficient en paramètres\n",
        "!pip install accelerate -U          # Bibliothèque Accelerate pour les performances\n",
        "\n",
        "# Installer des utilitaires pour le débogage et le formatage de la sortie console\n",
        "!pip install -q ipdb                # Débogueur interactif Python\n",
        "!pip install -q colorama            # Sortie de texte colorée dans le terminal\n",
        "\n",
        "# Importer des utilitaires système et mathématiques\n",
        "import os\n",
        "import math\n",
        "import urllib.request\n",
        "\n",
        "# Vérifier les accélérateurs connectés (GPU ou TPU) et configurer en conséquence\n",
        "if os.environ.get(\"COLAB_GPU\") and int(os.environ[\"COLAB_GPU\"]) > 0:\n",
        "    print(\"Un GPU est connecté.\")\n",
        "elif \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "    print(\"Un TPU est connecté.\")\n",
        "    import jax.tools.colab_tpu\n",
        "    jax.tools.colab_tpu.setup_tpu()\n",
        "else:\n",
        "    print(\"Seul le processeur (CPU) est connecté.\")\n",
        "\n",
        "# Éviter que l'allocation de mémoire GPU soit effectuée par JAX\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = \"false\"\n",
        "\n",
        "# Importer les bibliothèques pour le deep learning basé sur JAX\n",
        "import chex\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import optax\n",
        "\n",
        "# Importer les bibliothèques liées au NLP et aux modèles\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import datasets\n",
        "import peft\n",
        "\n",
        "# Importer les bibliothèques pour le traitement d'images et la visualisation\n",
        "from PIL import Image\n",
        "from livelossplot import PlotLosses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Importer des utilitaires supplémentaires pour travailler avec le texte et les modèles\n",
        "import torch\n",
        "import torchvision\n",
        "import itertools\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Télécharger une image d'exemple à utiliser dans le notebook\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://images.unsplash.com/photo-1529778873920-4da4926a72c2?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8Y3V0ZSUyMGNhdHxlbnwwfHwwfHw%3D&w=1000&q=80\",\n",
        "    \"cat.png\",\n",
        ")\n",
        "\n",
        "# Importer les bibliothèques pour le prétraitement NLP et le travail avec des modèles pré-entraînés\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import nltk\n",
        "nltk.download(\"word2vec_sample\")\n",
        "\n",
        "# Importer les outils Hugging Face et les widgets IPython\n",
        "import huggingface_hub\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import colorama\n",
        "\n",
        "# Configurer Matplotlib pour générer des graphiques au format SVG pour une meilleure qualité\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmt3tp38G90A"
      },
      "source": [
        "## Entraînement de votre LLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Objectif d'entraînement <font color='green'>Intermédiaire</font>"
      ],
      "metadata": {
        "id": "jGKuXIJJyyo8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOSv1-3B_RGA"
      },
      "source": [
        "Une phrase n'est rien d'autre qu'une chaîne de mots. Un LLM vise à prédire le mot suivant en tenant compte du contexte actuel, c'est-à-dire des mots qui l'ont précédé.\n",
        "\n",
        "Voici l'idée de base :\n",
        "\n",
        "Pour calculer la probabilité d'une phrase complète \"mot1, mot2, ..., dernier mot\" apparaissant dans un contexte donné $c$, la procédure consiste à décomposer la phrase en mots individuels et à considérer la probabilité de chaque mot étant donné les mots qui le précèdent. Ces probabilités individuelles sont ensuite multipliées ensemble :\n",
        "\n",
        "$$\\text{Probabilité de la phrase} = \\text{Probabilité de mot1} \\times \\text{Probabilité de mot2} \\times \\ldots \\times \\text{Probabilité du dernier mot}$$\n",
        "\n",
        "Cette méthode est semblable à la construction d'une narration pièce par pièce en fonction de l'histoire précédente.\n",
        "\n",
        "Mathématiquement, cela s'exprime comme la vraisemblance (probabilité) d'une séquence de mots $y_1, y_2, ..., y_n$ dans un contexte donné $c$, ce qui est réalisé en multipliant les probabilités de chaque mot $y_t$ calculées étant donné les prédécesseurs ($y_{<t}$) et le contexte $c$ :\n",
        "\n",
        "$$\n",
        "P\\left(y_{1}, y_{2}, \\ldots, y_{n}, \\mid c\\right)=\\prod_{t=1}^{n} P\\left(y_{t} \\mid y_{<t}, c\\right)\n",
        "$$\n",
        "\n",
        "Ici $y_{<t}$ représente la séquence $y_1, y_2, ..., y_{t-1}$, tandis que $c$ représente le contexte.\n",
        "\n",
        "Cela est analogue à résoudre un puzzle où la pièce suivante est placée prévisiblement en fonction de ce qui est déjà en place.\n",
        "\n",
        "Rappelez-vous que lors de l'entraînement d'un transformateur, nous ne travaillons pas avec des mots, mais avec des tokens. Pendant le processus d'entraînement, les paramètres du modèle sont affinés en calculant la perte de l'entropie croisée entre le token prédit et le token correct, puis en effectuant une rétropropagation. La perte pour l'étape temporelle \"t\" est calculée comme suit :\n",
        "\n",
        "$$ \\text{Perte}_t = - \\sum_{w \\in V} y_t\\log (\\hat{y}_t) $$\n",
        "\n",
        "Ici $y_t$ est le token réel à l'étape temporelle $t$, et $\\hat{y}_t$ est le token prédit par le modèle à la même étape temporelle. La perte pour l'ensemble de la phrase est ensuite calculée comme suit :\n",
        "\n",
        "$$ \\text{Perte de la phrase} = \\frac{1}{n} \\sum^{n}_{t=1} \\text{Perte}_t $$\n",
        "\n",
        "où $n$ est la longueur de la séquence.\n",
        "\n",
        "Ce processus itératif affine finalement les capacités prédictives du modèle au fil du temps.\n",
        "\n",
        "**Tâche de code** : Implémentez la fonction de perte d'entropie croisée ci-dessous.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXmjUYdDHseM"
      },
      "outputs": [],
      "source": [
        "def sequence_loss_fn(logits, targets):\n",
        "  '''\n",
        "  Calculer la perte d'entropie croisée entre l'ID de token prédit et l'ID réel.\n",
        "\n",
        "  Args:\n",
        "    logits: Un tableau de forme [batch_size, sequence_length, vocab_size]\n",
        "    targets: Les IDs de token réels que nous essayons de prédire, forme [batch_size, sequence_length]\n",
        "\n",
        "  Returns:\n",
        "    loss: Une valeur scalaire représentant la perte moyenne du lot\n",
        "  '''\n",
        "\n",
        "  target_labels = jax.nn.one_hot(targets, VOCAB_SIZE)\n",
        "  assert logits.shape == target_labels.shape\n",
        "\n",
        "  per_token_loss = -jnp.sum(target_labels* jnp.log_softmax(logits),axis=-1)\n",
        "\n",
        "  mask = jnp.greater(targets, 0)\n",
        "\n",
        "  masked_loos = jnp.sum(per_token_loss*mask)/jnp.sum(mask)\n",
        "\n",
        "  loss = ... # FINIR MOI\n",
        "\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cq5_4WN_RGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3fec88-2f58-446e-8436-217b810224f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il semble correct. Consultez la réponse ci-dessous pour comparer les méthodes.\n"
          ]
        }
      ],
      "source": [
        "# @title Exécutez-moi pour tester votre code\n",
        "VOCAB_SIZE = 25670\n",
        "targets = jnp.array([[0, 2, 0]])\n",
        "key = jax.random.PRNGKey(42)\n",
        "X = jax.random.normal(key, [1, 3, VOCAB_SIZE])\n",
        "loss = sequence_loss_fn(X, targets)\n",
        "real_loss = jnp.array(10.966118)\n",
        "assert jnp.allclose(real_loss, loss), \"La valeur retournée n'est pas correcte\"\n",
        "print(\"Il semble correct. Consultez la réponse ci-dessous pour comparer les méthodes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cthfcbmC_RGA"
      },
      "outputs": [],
      "source": [
        "# @title Réponse à la tâche de code (Essayez de ne pas regarder avant d'avoir bien essayé !)\n",
        "def sequence_loss_fn(logits, targets):\n",
        "    \"\"\"Calculer la perte de séquence entre les logits prédits et les étiquettes cibles.\"\"\"\n",
        "\n",
        "    # Convertir les indices cibles en vecteurs encodés en one-hot.\n",
        "    # Chaque étiquette cible est convertie en un vecteur one-hot de taille VOCAB_SIZE.\n",
        "    target_labels = jax.nn.one_hot(targets, VOCAB_SIZE)\n",
        "\n",
        "    # Assurer que la forme des logits correspond à la forme des cibles encodées en one-hot.\n",
        "    # C'est important car nous devons calculer la perte sur les dimensions correspondantes.\n",
        "    assert logits.shape == target_labels.shape\n",
        "\n",
        "    # Créer un masque qui ignore les jetons de padding dans le calcul de la perte.\n",
        "    # Le masque est True (1) lorsque la valeur cible est supérieure à 0 et False (0) sinon.\n",
        "    mask = jnp.greater(targets, 0)\n",
        "\n",
        "    # Calculer la perte d'entropie croisée pour chaque jeton.\n",
        "    # L'entropie croisée est calculée comme le logarithme négatif de la probabilité de la classe correcte.\n",
        "    # jax.nn.log_softmax(logits) nous donne les probabilités logarithmiques pour chaque classe.\n",
        "    # Nous multiplions par les target_labels pour sélectionner la probabilité logarithmique de la classe correcte.\n",
        "    loss = -jnp.sum(target_labels * jax.nn.log_softmax(logits), axis=-1)\n",
        "\n",
        "    # Appliquer le masque à la perte pour ignorer les positions de padding et additionner les pertes.\n",
        "    # Nous normalisons ensuite la perte totale par le nombre de jetons non-padding.\n",
        "    loss = jnp.sum(loss * mask) / jnp.sum(mask)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CSfvGj__RGA"
      },
      "source": [
        "### 2. Entraînement des modèles <font color='blue'>Avancé</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIQ_aJGW_RGA"
      },
      "source": [
        "Dans la section suivante, nous définissons tous les processus nécessaires pour entraîner le modèle en utilisant l'objectif décrit ci-dessus. Une grande partie de cela concerne maintenant le travail requis pour effectuer l'entraînement avec FLAX.\n",
        "\n",
        "Ci-dessous, nous rassemblons le jeu de données sur lequel nous allons entraîner, qui est le jeu de données de Shakespeare de Karpathy. Il n'est pas si important de comprendre ce code, donc soit exécutez simplement la cellule pour charger les données, soit consultez le code si vous souhaitez le comprendre.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guMHAaSo_RGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf0166b-fffb-4256-cef5-8f8cf33c91cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-23 12:40:26--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-11-23 12:40:27 (28.6 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Créer le jeu de données Shakespeare et l'itérateur (optionnel, mais exécutez la cellule)\n",
        "\n",
        "# Astuce pour éviter les erreurs lors du téléchargement de tinyshakespeare.\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O input.txt\n",
        "\n",
        "class WordBasedAsciiDatasetForLLM:\n",
        "    \"\"\"Jeu de données en mémoire d'un fichier ASCII unique pour un modèle de type langage.\"\"\"\n",
        "\n",
        "    def __init__(self, path: str, batch_size: int, sequence_length: int):\n",
        "        \"\"\"Charger un fichier ASCII unique en mémoire.\"\"\"\n",
        "        self._batch_size = batch_size\n",
        "\n",
        "        with open(path, \"r\") as f:\n",
        "            corpus = f.read()\n",
        "\n",
        "        # Tokeniser en séparant le texte en mots\n",
        "        words = corpus.split()\n",
        "        self.vocab_size = len(set(words))  # Nombre de mots uniques\n",
        "\n",
        "        # Créer un mapping de mots vers des IDs uniques\n",
        "        self.word_to_id = {word: i for i, word in enumerate(set(words))}\n",
        "\n",
        "        # Stocker le mapping inverse des IDs vers les mots\n",
        "        self.id_to_word = {i: word for word, i in self.word_to_id.items()}\n",
        "\n",
        "        # Convertir les mots du corpus en leurs IDs correspondants\n",
        "        corpus = np.array([self.word_to_id[word] for word in words]).astype(np.int32)\n",
        "\n",
        "        crop_len = sequence_length + 1\n",
        "        num_batches, ragged = divmod(corpus.size, batch_size * crop_len)\n",
        "        if ragged:\n",
        "            corpus = corpus[:-ragged]\n",
        "        corpus = corpus.reshape([-1, crop_len])\n",
        "\n",
        "        if num_batches < 10:\n",
        "            raise ValueError(\n",
        "                f\"Seulement {num_batches} lots ; envisagez une séquence plus courte \"\n",
        "                \"ou un lot plus petit.\"\n",
        "            )\n",
        "\n",
        "        self._ds = WordBasedAsciiDatasetForLLM._infinite_shuffle(\n",
        "            corpus, batch_size * 10\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Générer le prochain mini-lot.\"\"\"\n",
        "        batch = [next(self._ds) for _ in range(self._batch_size)]\n",
        "        batch = np.stack(batch)\n",
        "        # Créer les paires observation/cible pour la modélisation du langage.\n",
        "        return dict(\n",
        "            input=batch[:, :-1], target=batch[:, 1:]\n",
        "        )\n",
        "\n",
        "    def ids_to_words(self, ids):\n",
        "        \"\"\"Convertir une séquence d'IDs de mots en mots.\"\"\"\n",
        "        return [self.id_to_word[id] for id in ids]\n",
        "\n",
        "    @staticmethod\n",
        "    def _infinite_shuffle(iterable, buffer_size):\n",
        "        \"\"\"Répéter et mélanger infiniment les données de l'itérable.\"\"\"\n",
        "        ds = itertools.cycle(iterable)\n",
        "        buf = [next(ds) for _ in range(buffer_size)]\n",
        "        random.shuffle(buf)\n",
        "        while True:\n",
        "            item = next(ds)\n",
        "            idx = random.randint(0, buffer_size - 1)  # Inclus.\n",
        "            result, buf[idx] = buf[idx], item\n",
        "            yield result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WBIFg51oQl0"
      },
      "source": [
        "Lets now look how our data is structured for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvH3XPM5_RGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289d6abb-ff9b-40e6-d657-b14ebd56a00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Entrée -----------\n",
            "TEXTE : yourselves? First Citizen: We cannot, sir, we are undone already. MENENIUS: I tell you, friends, most charitable care Have the patricians of you. For your wants, Your suffering in this dearth, you\n",
            "ASCII : [ 7165 21225  6386 12051 23400 20648 13970 24075 10855 21358  6834 18610\n",
            " 18866 10949 18923  5916  6643 23574  8974 18551 11030 11271 11796 16902\n",
            " 14743 10072 18124 14937  2720 24085 20056 24497]\n",
            "---------- Cible ----------\n",
            "TEXTE : First Citizen: We cannot, sir, we are undone already. MENENIUS: I tell you, friends, most charitable care Have the patricians of you. For your wants, Your suffering in this dearth, you may\n",
            "ASCII : [21225  6386 12051 23400 20648 13970 24075 10855 21358  6834 18610 18866\n",
            " 10949 18923  5916  6643 23574  8974 18551 11030 11271 11796 16902 14743\n",
            " 10072 18124 14937  2720 24085 20056 24497  1467]\n",
            "---------- Entrée -----------\n",
            "TEXTE : talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the patricians good. What authority surfeits on would relieve us: if\n",
            "ASCII : [23040  9771  5710  6845  3195 12720 23890 25627  6832  6386 19964 22626\n",
            "  2771 14683 21225  6386 12051 24075 18486  9009 23431 18551 11030  1356\n",
            " 10522 16499  8936  3618 13487 14241  3101 11828]\n",
            "---------- Cible ----------\n",
            "TEXTE : on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the patricians good. What authority surfeits on would relieve us: if they\n",
            "ASCII : [ 9771  5710  6845  3195 12720 23890 25627  6832  6386 19964 22626  2771\n",
            " 14683 21225  6386 12051 24075 18486  9009 23431 18551 11030  1356 10522\n",
            " 16499  8936  3618 13487 14241  3101 11828 10895]\n",
            "\n",
            " Taille totale du vocabulaire : 25670\n"
          ]
        }
      ],
      "source": [
        "# Échantillonner et examiner les données\n",
        "batch_size = 2\n",
        "seq_length = 32\n",
        "train_dataset = WordBasedAsciiDatasetForLLM(\"input.txt\", batch_size, seq_length)\n",
        "\n",
        "batch = next(train_dataset)\n",
        "\n",
        "for obs, target in zip(batch[\"input\"], batch[\"target\"]):\n",
        "    print(\"-\" * 10, \"Entrée\", \"-\" * 11)\n",
        "    print(\"TEXTE :\", ' '.join(train_dataset.ids_to_words(obs)))\n",
        "    print(\"ASCII :\", obs)\n",
        "    print(\"-\" * 10, \"Cible\", \"-\" * 10)\n",
        "    print(\"TEXTE :\", ' '.join(train_dataset.ids_to_words(target)))\n",
        "    print(\"ASCII :\", target)\n",
        "\n",
        "print(f\"\\n Taille totale du vocabulaire : {train_dataset.vocab_size}\")\n",
        "\n",
        "VOCAB_SIZE = train_dataset.vocab_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9vzee53_RGB"
      },
      "source": [
        "Ensuite, entraînons notre LLM et voyons comment il se comporte pour produire du texte shakespearien. Tout d'abord, nous allons définir ce qui se passe à chaque étape d'entraînement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuYBCkekgDw"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "@functools.partial(jax.jit, static_argnums=(3, 4))\n",
        "def train_step(params, optimizer_state, batch, apply_fn, update_fn):\n",
        "    \"\"\"\n",
        "    Effectuer une étape d'entraînement.\n",
        "\n",
        "    Args:\n",
        "        params: Les paramètres actuels du modèle.\n",
        "        optimizer_state: L'état actuel de l'optimiseur.\n",
        "        batch: Un dictionnaire contenant les données d'entrée et les étiquettes cibles pour le batch.\n",
        "        apply_fn: La fonction utilisée pour appliquer le modèle aux entrées.\n",
        "        update_fn: La fonction utilisée pour mettre à jour les paramètres du modèle en fonction des gradients.\n",
        "\n",
        "    Returns:\n",
        "        Paramètres mis à jour, état de l'optimiseur mis à jour, et la perte calculée pour le batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def loss_fn(params):\n",
        "        # Obtenez la longueur de la séquence (T) à partir des données d'entrée.\n",
        "        T = batch['input'].shape[1]\n",
        "\n",
        "        # Appliquez le modèle aux données d'entrée, en utilisant un masque triangulaire inférieur pour imposer la causalité.\n",
        "        # jnp.tril(np.ones((T, T))) crée une matrice triangulaire inférieure de uns.\n",
        "        logits = apply_fn(params, batch['input'], jnp.tril(np.ones((T, T))))\n",
        "\n",
        "        # Calculez la perte entre les logits prédits et les étiquettes cibles.\n",
        "        loss = sequence_loss_fn(logits, batch['target'])\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Calculez la perte et ses gradients par rapport aux paramètres.\n",
        "    loss, gradients = jax.value_and_grad(loss_fn)(params)\n",
        "\n",
        "    # Mettez à jour l'état de l'optimiseur et calculez les mises à jour des paramètres en fonction des gradients.\n",
        "    updates, optimizer_state = update_fn(gradients, optimizer_state)\n",
        "\n",
        "    # Appliquez les mises à jour aux paramètres.\n",
        "    params = optax.apply_updates(params, updates)\n",
        "\n",
        "    # Retournez les paramètres mis à jour, l'état de l'optimiseur, et la perte pour le batch.\n",
        "    return params, optimizer_state, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtKWzKIAkfYU"
      },
      "source": [
        "Nous allons maintenant initialiser notre optimiseur et notre modèle. N'hésitez pas à expérimenter avec les hyperparamètres pendant la pratique.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_frequency_pe_matrix(longueur_sequence_tokens, taille_embedding_tokens):\n",
        "\n",
        "    assert taille_embedding_tokens % 2 == 0, \"la taille de l'embedding des tokens doit être divisible par deux\"\n",
        "\n",
        "    P = jnp.zeros((longueur_sequence_tokens, taille_embedding_tokens))\n",
        "    positions = jnp.arange(0, longueur_sequence_tokens)[:, jnp.newaxis]\n",
        "\n",
        "    i = jnp.arange(0, taille_embedding_tokens, 2)\n",
        "    pas_frequence = jnp.exp(i * (-math.log(10000.0) / taille_embedding_tokens))\n",
        "    frequences = positions * pas_frequence\n",
        "\n",
        "    P = P.at[:, 0::2].set(jnp.sin(frequences))\n",
        "    P = P.at[:, 1::2].set(jnp.cos(frequences))\n",
        "\n",
        "    return P"
      ],
      "metadata": {
        "id": "VgwaEmdHGJ5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    \"\"\"\n",
        "    Attention à produit scalaire échelonné avec un masque causal\n",
        "    (se concentrant uniquement sur les positions précédentes)\n",
        "    \"\"\"\n",
        "    d_k = key.shape[-1]\n",
        "    T_k = key.shape[-2]\n",
        "    T_q = query.shape[-2]\n",
        "\n",
        "    # obtenir les logits échelonnés en utilisant le produit scalaire comme précédemment\n",
        "    logits = jnp.matmul(query, jnp.swapaxes(key, -2, -1))\n",
        "    scaled_logits = logits / jnp.sqrt(d_k)\n",
        "\n",
        "    # ajouter un masque optionnel où les valeurs le long du masque sont définies à -inf\n",
        "    if mask is not None:\n",
        "        scaled_logits = jnp.where(mask[:T_q, :T_k], scaled_logits, -jnp.inf)\n",
        "\n",
        "    # calculer les poids d'attention via softmax\n",
        "    attention_weights = jax.nn.softmax(scaled_logits, axis=-1)\n",
        "\n",
        "    # faire la somme avec les valeurs pour obtenir la sortie\n",
        "    output = jnp.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "1wsXLjJ9FWrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceToQKV(nn.Module):\n",
        "  taille_sortie: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, X):\n",
        "\n",
        "    # définir la méthode d'initialisation des poids\n",
        "    initialisateur = nn.initializers.variance_scaling(scale=0.5, mode=\"fan_in\", distribution=\"truncated_normal\")\n",
        "\n",
        "    # initialiser trois couches linéaires pour faire les transformations QKV.\n",
        "    # note : cela pourrait aussi être une seule couche, comment pensez-vous que vous le feriez ?\n",
        "    couche_q = nn.Dense(self.taille_sortie, kernel_init=initialisateur)\n",
        "    couche_k = nn.Dense(self.taille_sortie, kernel_init=initialisateur)\n",
        "    couche_v = nn.Dense(self.taille_sortie, kernel_init=initialisateur)\n",
        "\n",
        "    # transformer et retourner les matrices\n",
        "    Q = couche_q(X)\n",
        "    K = couche_k(X)\n",
        "    V = couche_v(X)\n",
        "\n",
        "    return Q, K, V\n"
      ],
      "metadata": {
        "id": "WuHCXSYKFp4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    num_heads: int  # Nombre de têtes d'attention\n",
        "    d_m: int  # Dimension des embeddings du modèle\n",
        "\n",
        "    def setup(self):\n",
        "        # Initialiser le module de transformation de la séquence en QKV (requête, clé, valeur)\n",
        "        self.sequence_to_qkv = SequenceToQKV(self.d_m)\n",
        "\n",
        "        # Définir l'initialiseur pour les poids de la couche linéaire de sortie\n",
        "        initializer = nn.initializers.variance_scaling(\n",
        "            scale=0.5, mode=\"fan_in\", distribution=\"truncated_normal\"\n",
        "        )\n",
        "\n",
        "        # Initialiser la couche de projection de sortie Wo (utilisée après l'attention)\n",
        "        self.Wo = nn.Dense(self.d_m, kernel_init=initializer)\n",
        "\n",
        "    def __call__(self, X=None, Q=None, K=None, V=None, mask=None, return_weights=False):\n",
        "        # Si Q, K ou V ne sont pas fournis, utiliser l'entrée X pour les générer\n",
        "        if None in [Q, K, V]:\n",
        "            assert not X is None, \"X doit être fourni si Q, K ou V ne sont pas fournis\"\n",
        "\n",
        "            # Générer les matrices Q, K et V à partir de l'entrée X\n",
        "            Q, K, V = self.sequence_to_qkv(X)\n",
        "\n",
        "        # Extraire la taille du lot (B), la longueur de la séquence (T) et la taille de l'embedding (d_m)\n",
        "        B, T, d_m = K.shape\n",
        "\n",
        "        # Calculer la taille de l'embedding de chaque tête d'attention (d_m / num_heads)\n",
        "        head_size = d_m // self.num_heads\n",
        "\n",
        "        # Reshaper Q, K, V pour avoir des dimensions séparées pour les têtes\n",
        "        # B, T, d_m -> B, T, num_heads, head_size -> B, num_heads, T, head_size\n",
        "        q_heads = Q.reshape(B, T, self.num_heads, head_size).swapaxes(1, 2)\n",
        "        k_heads = K.reshape(B, T, self.num_heads, head_size).swapaxes(1, 2)\n",
        "        v_heads = V.reshape(B, T, self.num_heads, head_size).swapaxes(1, 2)\n",
        "\n",
        "        # Appliquer l'attention à produit scalaire échelonné à chaque tête\n",
        "        attention, attention_weights = scaled_dot_product_attention(\n",
        "            q_heads, k_heads, v_heads, mask\n",
        "        )\n",
        "\n",
        "        # Reshaper la sortie de l'attention à ses dimensions originales\n",
        "        # (B, num_heads, T, head_size) -> (B, T, num_heads, head_size) -> (B, T, d_m)\n",
        "        attention = attention.swapaxes(1, 2).reshape(B, T, d_m)\n",
        "\n",
        "        # Appliquer la transformation linéaire de sortie Wo à la sortie de l'attention\n",
        "        X_new = self.Wo(attention)\n",
        "\n",
        "        # Si return_weights est True, retourner à la fois la sortie transformée et les poids d'attention\n",
        "        if return_weights:\n",
        "            return X_new, attention_weights\n",
        "        else:\n",
        "            # Sinon, retourner uniquement la sortie transformée\n",
        "            return X_new\n"
      ],
      "metadata": {
        "id": "gJyjEbeMFVUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddNorm(nn.Module):\n",
        "    \"\"\"Un bloc qui implémente l'opération 'Add and Norm' utilisée dans les transformers.\"\"\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, processed_x):\n",
        "      # Étape 1 : Ajouter l'entrée originale (x) à l'entrée traitée (processed_x).\n",
        "      added = x + processed_x\n",
        "\n",
        "      # Étape 2 : Appliquer une normalisation par couche au résultat de l'addition.\n",
        "      # - LayerNorm aide à stabiliser et améliorer le processus d'entraînement en normalisant la sortie.\n",
        "      # - reduction_axes=-1 indique que la normalisation est appliquée sur la dernière dimension (généralement la dimension de l'embedding).\n",
        "      # - use_scale=True et use_bias=True permettent à la couche d'apprendre des paramètres d'échelle et de biais pour un ajustement plus précis.\n",
        "      normalised = nn.LayerNorm(reduction_axes=-1, use_scale=True, use_bias=True)\n",
        "\n",
        "      # Retourner le résultat normalisé.\n",
        "      return normalised(added)"
      ],
      "metadata": {
        "id": "IREB57lyFIuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "    \"\"\"Un MLP (Multi-Layer Perceptron) à 2 couches qui commence par élargir la taille de l'entrée, puis la réduit à nouveau.\"\"\"\n",
        "\n",
        "    # widening_factor contrôle l'expansion de la dimension de l'entrée dans la première couche.\n",
        "    widening_factor: int = 4\n",
        "\n",
        "    # init_scale contrôle le facteur d'échelle pour l'initialisation des poids.\n",
        "    init_scale: float = 0.25\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      # Obtenir la taille de la dernière dimension de l'entrée (taille de l'embedding).\n",
        "      d_m = x.shape[-1]\n",
        "\n",
        "      # Calculer la taille de la première couche en multipliant la taille de l'embedding par le facteur d'élargissement.\n",
        "      layer1_size = self.widening_factor * d_m\n",
        "\n",
        "      # Initialiser les poids des deux couches en utilisant un initialiseur basé sur la variance.\n",
        "      initializer = nn.initializers.variance_scaling(\n",
        "          scale=self.init_scale, mode='fan_in', distribution='truncated_normal',\n",
        "      )\n",
        "\n",
        "      # Définir la première couche dense, qui élargit la taille de l'entrée.\n",
        "      layer1 = nn.Dense(layer1_size, kernel_init=initializer)\n",
        "\n",
        "      # Définir la deuxième couche dense, qui réduit la taille pour revenir à la dimension d'origine.\n",
        "      layer2 = nn.Dense(d_m, kernel_init=initializer)\n",
        "\n",
        "      # Appliquer la première couche dense suivie d'une fonction d'activation GELU.\n",
        "      x = jax.nn.gelu(layer1(x))\n",
        "\n",
        "      # Appliquer la deuxième couche dense pour ramener les données à leur dimension d'origine.\n",
        "      x = layer2(x)\n",
        "\n",
        "      # Retourner la sortie finale.\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "ADg7Y3ZqFUKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Bloc décodeur du Transformer.\n",
        "\n",
        "    Args:\n",
        "        num_heads: Le nombre de têtes d'attention dans le bloc Multi-Head\n",
        "        Attention (MHA).\n",
        "        d_m: La taille des embeddings des tokens.\n",
        "        widening_factor: Le facteur par lequel la taille de la couche cachée\n",
        "        est augmentée dans le MLP.\n",
        "    \"\"\"\n",
        "\n",
        "    num_heads: int\n",
        "    d_m: int\n",
        "    widening_factor: int = 4\n",
        "\n",
        "    def setup(self):\n",
        "      # Initialiser le bloc Multi-Head Attention (MHA)\n",
        "      self.mha = MultiHeadAttention(self.num_heads, self.d_m)\n",
        "\n",
        "      # Initialiser les blocs AddNorm pour les connexions résiduelles\n",
        "      # et la normalisation\n",
        "      self.add_norm1 = AddNorm()  # Premier bloc AddNorm après MHA\n",
        "      self.add_norm2 = AddNorm()  # Deuxième bloc AddNorm après le MLP\n",
        "\n",
        "      # Initialiser le FeedForwardBlock (MLP) qui traite les données\n",
        "      # après l'attention\n",
        "      self.MLP = FeedForwardBlock(widening_factor=self.widening_factor)\n",
        "\n",
        "    def __call__(self, X, mask=None, return_att_weight=True):\n",
        "      \"\"\"\n",
        "      Passage en avant à travers le DecoderBlock.\n",
        "\n",
        "      Args:\n",
        "          X: Lot de tokens d'entrée envoyés dans le décodeur,\n",
        "          forme [B, T_decoder, d_m]\n",
        "          mask [optionnel, par défaut=None]: Masque pour contrôler les positions\n",
        "          que l'attention est autorisée à considérer,\n",
        "          forme [T_decoder, T_decoder].\n",
        "          return_att_weight [optionnel, par défaut=True]: Si True,\n",
        "          retourne les poids d'attention avec la sortie.\n",
        "\n",
        "      Returns:\n",
        "          Si return_att_weight est True, retourne un tuple (X,\n",
        "          attention_weights_1).\n",
        "          Sinon, retourne les représentations des tokens traités X.\n",
        "      \"\"\"\n",
        "      # Appliquer l'attention multi-tête aux tokens d'entrée (X)\n",
        "      # avec un masquage optionnel\n",
        "      attention, attention_weights_1 = self.mha(X, mask=mask, return_weights=True)\n",
        "\n",
        "      # Appliquer le premier bloc AddNorm (ajoute l'entrée originale X\n",
        "      # et normalise)\n",
        "      X = self.add_norm1(X, attention)\n",
        "\n",
        "      # Passer le résultat à travers le FeedForwardBlock (MLP)\n",
        "      # pour traiter davantage les données\n",
        "      projection = self.MLP(X)\n",
        "\n",
        "      # Appliquer le deuxième bloc AddNorm (ajoute l'entrée de l'étape\n",
        "      # précédente et normalise)\n",
        "      X = self.add_norm2(X, projection)\n",
        "\n",
        "      # Retourner la sortie finale X, et éventuellement les poids d'attention\n",
        "      return (X, attention_weights_1) if return_att_weight else X"
      ],
      "metadata": {
        "id": "Po2EMcSTEnQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLM(nn.Module):\n",
        "    \"\"\"\n",
        "    Modèle Transformer composé de plusieurs couches de blocs décodeurs.\n",
        "\n",
        "    Args:\n",
        "        num_heads: Nombre de têtes d'attention dans chaque bloc Multi-Head\n",
        "        Attention (MHA).\n",
        "        num_layers: Nombre de blocs décodeurs dans le modèle.\n",
        "        d_m: Dimensionnalité des embeddings des tokens.\n",
        "        vocab_size: Taille du vocabulaire (nombre de tokens uniques).\n",
        "        widening_factor: Facteur par lequel la taille de la couche cachée\n",
        "        est augmentée dans le MLP.\n",
        "    \"\"\"\n",
        "    num_heads: int\n",
        "    num_layers: int\n",
        "    d_m: int\n",
        "    vocab_size: int\n",
        "    widening_factor: int = 4\n",
        "\n",
        "    def setup(self):\n",
        "        # Initialiser une liste de blocs décodeurs, un pour chaque\n",
        "        # couche du modèle\n",
        "        self.blocks = [\n",
        "            DecoderBlock(self.num_heads, self.d_m, self.widening_factor)\n",
        "            for _ in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "        # Initialiser une couche d'embedding pour convertir les IDs de\n",
        "        # tokens en embeddings de tokens\n",
        "        self.embedding = nn.Embed(num_embeddings=self.vocab_size, features=self.d_m)\n",
        "\n",
        "        # Initialiser une couche dense pour prédire le prochain token\n",
        "        # dans la séquence\n",
        "        self.pred_layer = nn.Dense(self.vocab_size)\n",
        "\n",
        "    def __call__(self, X, mask=None, return_att_weights=False):\n",
        "        \"\"\"\n",
        "        Passage en avant à travers le modèle LLM.\n",
        "\n",
        "        Args:\n",
        "            X: Lot d'IDs de tokens d'entrée, forme [B, T_decoder]\n",
        "            où B est la taille du lot et T_decoder est la longueur\n",
        "            de la séquence.\n",
        "            mask [optionnel, par défaut=None]: Masque pour contrôler les\n",
        "            positions sur lesquelles l'attention peut se concentrer,\n",
        "            forme [T_decoder, T_decoder].\n",
        "            return_att_weights [optionnel, par défaut=False]: Indique\n",
        "            si les poids d'attention doivent être retournés.\n",
        "\n",
        "        Returns:\n",
        "            logits: Les probabilités prédites pour chaque token dans\n",
        "            le vocabulaire.\n",
        "            Si return_att_weights est True, retourne également\n",
        "            les poids d'attention.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convertir les IDs de tokens en embeddings (forme\n",
        "        # [B, T_decoder, d_m])\n",
        "        X = self.embedding(X)\n",
        "\n",
        "        # Obtenir la longueur de la séquence d'entrée\n",
        "        sequence_len = X.shape[-2]\n",
        "\n",
        "        # Générer des encodages positionnels et les ajouter aux\n",
        "        # embeddings des tokens\n",
        "        positions = return_frequency_pe_matrix(sequence_len, self.d_m)\n",
        "        X = X + positions\n",
        "\n",
        "        # Initialiser une liste pour stocker les poids d'attention\n",
        "        # si nécessaire\n",
        "        if return_att_weights:\n",
        "            att_weights = []\n",
        "\n",
        "        # Passer les embeddings à travers chaque bloc décodeur\n",
        "        # en séquence\n",
        "        for block in self.blocks:\n",
        "            out = block(X, mask, return_att_weights)\n",
        "            if return_att_weights:\n",
        "                # Si on retourne les poids d'attention, déballer la sortie\n",
        "                X = out[0]\n",
        "                att_weights.append(out[1])\n",
        "            else:\n",
        "                # Sinon, mettre à jour simplement l'entrée pour le\n",
        "                # bloc suivant\n",
        "                X = out\n",
        "\n",
        "        # Appliquer une couche dense suivie d'un log softmax pour obtenir\n",
        "        # les logits (probabilités prédites des tokens)\n",
        "        logits = nn.log_softmax(self.pred_layer(X))\n",
        "\n",
        "        # Retourner les logits, et éventuellement, les poids d'attention\n",
        "        return logits if not return_att_weights else (logits, jnp.array(att_weights).swapaxes(0, 1))"
      ],
      "metadata": {
        "id": "ieW0qU66DhHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o3q-BZX_RGB"
      },
      "outputs": [],
      "source": [
        "# Définir tous les hyperparamètres\n",
        "d_model = 128            # Dimension des embeddings de tokens (d_m)\n",
        "num_heads = 4            # Nombre de têtes d'attention dans Multi-Head Attention\n",
        "num_layers = 1           # Nombre de blocs décodeurs dans le modèle\n",
        "widening_factor = 2      # Facteur d'élargissement de la taille de la couche cachée dans le MLP\n",
        "LR = 2e-3                # Taux d'apprentissage pour l'optimiseur\n",
        "batch_size = 32          # Nombre d'échantillons par lot d'entraînement\n",
        "seq_length = 64          # Longueur de chaque séquence d'entrée (nombre de tokens)\n",
        "\n",
        "# Préparer les données d'entraînement\n",
        "train_dataset = WordBasedAsciiDatasetForLLM(\"input.txt\", batch_size, seq_length)\n",
        "vocab_size = train_dataset.vocab_size  # Obtenir la taille du vocabulaire à partir du dataset\n",
        "batch = next(train_dataset)            # Obtenir le premier lot de données d'entrée\n",
        "\n",
        "# Définir la clé du générateur de nombres aléatoires pour l'initialisation du modèle\n",
        "rng = jax.random.PRNGKey(42)\n",
        "\n",
        "# Initialiser le modèle LLM avec les hyperparamètres spécifiés\n",
        "llm = LLM(num_heads=num_heads, num_layers=num_layers, d_m=d_model, vocab_size=vocab_size, widening_factor=widening_factor)\n",
        "\n",
        "# Créer un masque causal pour s'assurer que le modèle ne se concentre que sur les tokens précédents\n",
        "mask = jnp.tril(np.ones((batch['input'].shape[1], batch['input'].shape[1])))\n",
        "\n",
        "# Initialiser les paramètres du modèle en utilisant le premier lot de données d'entrée et le masque\n",
        "params = llm.init(rng, batch['input'], mask)\n",
        "\n",
        "# Configurer l'optimiseur en utilisant l'algorithme d'optimisation Adam avec le taux d'apprentissage spécifié\n",
        "optimizer = optax.adam(LR, b1=0.9, b2=0.99)\n",
        "optimizer_state = optimizer.init(params)  # Initialiser l'état de l'optimiseur avec les paramètres du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bPEFakxmvsM"
      },
      "source": [
        "Now we train! This will take a few minutes..\n",
        "While it trains, have you greeted your neighbor yet?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUAS6tie_RGB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "f4f87d1a-5857-4a92-f7d9-6152507e58d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"440.08pt\" height=\"567.034375pt\" viewBox=\"0 0 440.08 567.034375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-11-23T12:51:46.498539</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.8.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 567.034375 \nL 440.08 567.034375 \nL 440.08 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 529.478125 \nL 432.88 529.478125 \nL 432.88 22.318125 \nL 26.925 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mc380e9f41f\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"45.3775\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(42.19625 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"113.093096\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(106.730596 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"180.808693\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(174.446193 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"248.524289\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(242.161789 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"316.239885\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(309.877385 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mc380e9f41f\" x=\"383.955482\" y=\"529.478125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(374.411732 544.076562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(214.674375 557.754687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m200438ecda\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"513.546079\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 517.345298) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"425.803674\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(13.5625 429.602893) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"338.06127\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 4 -->\n      <g transform=\"translate(13.5625 341.860488) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"250.318865\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 6 -->\n      <g transform=\"translate(13.5625 254.118084) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"162.57646\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 8 -->\n      <g transform=\"translate(13.5625 166.375679) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m200438ecda\" x=\"26.925\" y=\"74.834056\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 78.633274) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 45.3775 45.370852 \nL 48.76328 144.1198 \nL 52.14906 166.375992 \nL 55.534839 168.084376 \nL 58.920619 178.222889 \nL 62.306399 177.676557 \nL 65.692179 181.470838 \nL 69.077959 187.108308 \nL 72.463739 190.22572 \nL 75.849518 199.233559 \nL 79.235298 215.268127 \nL 82.621078 223.30884 \nL 86.006858 236.038098 \nL 89.392638 253.972483 \nL 92.778417 261.093475 \nL 96.164197 270.665971 \nL 99.549977 286.284033 \nL 102.935757 293.037365 \nL 106.321537 298.534529 \nL 109.707317 312.203445 \nL 113.093096 317.308578 \nL 116.478876 320.493204 \nL 119.864656 331.959996 \nL 123.250436 336.491037 \nL 126.636216 338.328337 \nL 130.021995 347.390787 \nL 133.407775 351.778436 \nL 136.793555 353.349516 \nL 140.179335 361.789038 \nL 143.565115 366.366709 \nL 146.950894 367.876756 \nL 150.336674 374.93023 \nL 153.722454 380.849871 \nL 157.108234 382.782543 \nL 160.494014 389.892165 \nL 163.879794 394.615498 \nL 167.265573 396.559926 \nL 170.651353 403.760066 \nL 174.037133 409.559107 \nL 177.422913 410.540029 \nL 180.808693 416.375313 \nL 184.194472 422.582 \nL 187.580252 423.198746 \nL 190.966032 429.559876 \nL 194.351812 433.369099 \nL 197.737592 433.810383 \nL 201.123372 439.870875 \nL 204.509151 444.14794 \nL 207.894931 443.82714 \nL 211.280711 449.43106 \nL 214.666491 453.525367 \nL 218.052271 453.51359 \nL 221.43805 457.854992 \nL 224.82383 461.175416 \nL 228.20961 461.793386 \nL 231.59539 465.393027 \nL 234.98117 468.528451 \nL 238.36695 468.35529 \nL 241.752729 472.943567 \nL 245.138509 474.560095 \nL 248.524289 474.415798 \nL 251.910069 477.981126 \nL 255.295849 480.744827 \nL 258.681628 480.637442 \nL 262.067408 482.866657 \nL 265.453188 485.277273 \nL 268.838968 484.880152 \nL 272.224748 487.115465 \nL 275.610528 489.416528 \nL 278.996307 489.170202 \nL 282.382087 490.363602 \nL 285.767867 492.328863 \nL 289.153647 492.963073 \nL 292.539427 494.016575 \nL 295.925206 494.975295 \nL 299.310986 495.561907 \nL 302.696766 496.395612 \nL 306.082546 497.042082 \nL 309.468326 498.070966 \nL 312.854106 498.404025 \nL 316.239885 499.283441 \nL 319.625665 499.66618 \nL 323.011445 499.857643 \nL 326.397225 500.756657 \nL 329.783005 501.236457 \nL 333.168784 501.102416 \nL 336.554564 501.900372 \nL 339.940344 503.035016 \nL 343.326124 502.82153 \nL 346.711904 503.148343 \nL 350.097683 503.685165 \nL 353.483463 503.531434 \nL 356.869243 503.725872 \nL 360.255023 503.841052 \nL 363.640803 503.736974 \nL 367.026583 504.241687 \nL 370.412362 504.717279 \nL 373.798142 504.744642 \nL 377.183922 505.081933 \nL 380.569702 505.812153 \nL 383.955482 505.192313 \nL 387.341261 505.563609 \nL 390.727041 505.876506 \nL 394.112821 505.869548 \nL 397.498601 506.061056 \nL 400.884381 506.265981 \nL 404.270161 505.679928 \nL 407.65594 505.879926 \nL 411.04172 506.425398 \nL 414.4275 506.269135 \n\" clip-path=\"url(#p6eacdd66ad)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 529.478125 \nL 26.925 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 432.88 529.478125 \nL 432.88 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 529.478125 \nL 432.88 529.478125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 22.318125 \nL 432.88 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- Loss -->\n    <g transform=\"translate(216.741875 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-4c\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 374.564375 284.737187 \nL 425.88 284.737187 \nQ 427.88 284.737187 427.88 282.737187 \nL 427.88 269.059062 \nQ 427.88 267.059062 425.88 267.059062 \nL 374.564375 267.059062 \nQ 372.564375 267.059062 372.564375 269.059062 \nL 372.564375 282.737187 \nQ 372.564375 284.737187 374.564375 284.737187 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_14\">\n     <path d=\"M 376.564375 275.1575 \nL 386.564375 275.1575 \nL 396.564375 275.1575 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- loss -->\n     <g transform=\"translate(404.564375 278.6575) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6eacdd66ad\">\n   <rect x=\"26.925\" y=\"22.318125\" width=\"405.955\" height=\"507.16\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss\n",
            "\tloss             \t (min:    0.162, max:   10.672, cur:    0.166)\n"
          ]
        }
      ],
      "source": [
        "plotlosses = PlotLosses()\n",
        "\n",
        "MAX_STEPS = 3500\n",
        "LOG_EVERY = 32\n",
        "losses = []\n",
        "VOCAB_SIZE = 25670\n",
        "\n",
        "# Boucle d'entraînement\n",
        "for step in range(MAX_STEPS):\n",
        "    batch = next(train_dataset)\n",
        "    params, optimizer_state, loss = train_step(\n",
        "        params, optimizer_state, batch, llm.apply, optimizer.update)\n",
        "    losses.append(loss)\n",
        "    if step % LOG_EVERY == 0:\n",
        "        loss_ = jnp.array(losses).mean()\n",
        "        plotlosses.update(\n",
        "            {\n",
        "                \"loss\": loss_,\n",
        "            }\n",
        "        )\n",
        "        plotlosses.send()\n",
        "        losses = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGv9c2AFmF4V"
      },
      "source": [
        "### 3. Inspecter le LLM entraîné <font color='orange'>Débutant</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfq61gim_RGB"
      },
      "source": [
        "**Rappel :** n'oubliez pas d'exécuter tout le code présenté jusqu'à présent dans cette section avant de lancer les cellules ci-dessous !\n",
        "\n",
        "Générons maintenant un peu de texte et voyons comment notre modèle a performé. NE STOPPEZ PAS LA CELLULE UNE FOIS QU'ELLE EST EN COURS D'EXÉCUTION, CELA FERA PLANTER LA SESSION.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lt8HTS__RGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c0a317-a3cf-4c23-bdb1-b8554b33dc25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "life an hour Hath been a lamb indeed, that baes like a bear. MENENIUS: He's a"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "\n",
        "@functools.partial(jax.jit, static_argnums=(2, ))\n",
        "def generate_prediction(params, input, apply_fn):\n",
        "  logits = apply_fn(params, input)\n",
        "  argmax_out = jnp.argmax(logits, axis=-1)\n",
        "  return argmax_out[0][-1].astype(int)\n",
        "\n",
        "def generate_random_shakespeare(llm, params, id_2_word, word_2_id):\n",
        "    '''\n",
        "    Get the model output\n",
        "    '''\n",
        "\n",
        "    prompt = \"life\"\n",
        "    print(prompt, end=\"\")\n",
        "    tokens = prompt.split()\n",
        "\n",
        "    # predict and append\n",
        "    for i in range(15):\n",
        "      input = jnp.array([[word_2_id[t] for t in tokens]]).astype(int)\n",
        "      prediction = generate_prediction(params, input, llm.apply)\n",
        "      prediction = id_2_word[int(prediction)]\n",
        "      tokens.append(prediction)\n",
        "      print(\" \"+prediction, end=\"\")\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "id_2_word = train_dataset.id_to_word\n",
        "word_2_id = train_dataset.word_to_id\n",
        "\n",
        "generated_shakespeare = generate_random_shakespeare(llm, params, id_2_word, word_2_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOwNuMRf_RGC"
      },
      "source": [
        "Enfin, nous avons implémenté tout ce qui précède en prenant l'ID de jeton avec la probabilité maximale d'être correct. C'est ce qu'on appelle le décodage gourmand, car nous avons uniquement pris le jeton le plus probable. Cela a bien fonctionné dans ce cas, mais il y a des situations où cette approche gourmande peut dégrader les performances, notamment lorsque nous souhaitons générer un texte réaliste.\n",
        "\n",
        "Il existe d'autres méthodes pour échantillonner à partir du décodeur, avec un algorithme célèbre étant la recherche par faisceau (beam search). Nous fournissons ci-dessous des ressources pour ceux qui souhaitent en savoir plus à ce sujet.\n",
        "\n",
        "[Décodage Gourmand](https://www.youtube.com/watch?v=DW5C3eqAFQM&list=PLmZlBIcArwhPHmHzyM_cZJQ8_v5paQJTV&index=4)\n",
        "\n",
        "[Recherche par Faisceau](https://www.youtube.com/watch?v=uG3xoYNo3HM&list=PLmZlBIcArwhPHmHzyM_cZJQ8_v5paQJTV&index=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**"
      ],
      "metadata": {
        "id": "15296-QL3-y3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3YG7QOZD-B"
      },
      "source": [
        "**Résumé :**\n",
        "\n",
        "Vous avez maintenant maîtrisé l'essentiel du fonctionnement d'un Large Language Model (LLM) ! Ces outils puissants ont le potentiel de transformer un large éventail de tâches. Cependant, comme tout modèle de deep learning, leur efficacité réside dans leur application aux bons problèmes avec les bonnes données.\n",
        "\n",
        "Prêt à passer au niveau supérieur ? Plongez dans le fine-tuning de vos propres LLMs et libérez encore plus de potentiel ! Je vous recommande vivement d'explorer le tutoriel de l'année dernière sur les méthodes de fine-tuning efficaces pour obtenir une vue d'ensemble des techniques avancées. Le voyage ne s'arrête pas là—il y a encore tant à découvrir ! [LLMs pour Tous 2023](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/large_language_models.ipynb)\n",
        "\n",
        "Le monde des LLMs est à vous—allez créer quelque chose d'incroyable ! 🌟🚀\n",
        "\n",
        "**Prochaines étapes :**\n",
        "\n",
        "[**Fine-tuning Efficace des LLMs avec Hugging Face**](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/large_language_models.ipynb)\n",
        "\n",
        "**Références :** pour des références supplémentaires, consultez les liens mentionnés dans les sections spécifiques de ce colab.\n",
        "\n",
        "* [Article \"Attention is all you need\"](https://arxiv.org/abs/1706.03762)\n",
        "* [Vidéos supplémentaires sur les transformers](https://www.youtube.com/playlist?list=PLmZlBIcArwhOPR2s-FIR7WoqNaBML233s)\n",
        "* [Article LoRA](https://arxiv.org/abs/2106.09685)\n",
        "* [RLHF](https://huggingface.co/blog/rlhf) (comment ChatGPT a été entraîné)\n",
        "* [Extension de la longueur du contexte](https://kaiokendev.github.io/context)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "145833166d986a8417df3c7acb65d917d84b716b5a452e57fcacdc66f1a168c9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}